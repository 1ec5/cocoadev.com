General/FloatingPoint is the standard way to represent non-integer numbers in computers. General/FloatingPoint is works by representing numbers in a manner resembling scientific notation, with a mantissa and an exponent, along with a bit to indicate sign. Historically, General/FloatingPoint math has been significantly slower than integer math, particularly in machines without specialized General/FloatingPoint hardware, but all modern desktop processors include fast General/FloatingPoint units.

General/FloatingPoint numbers in C code are created by using the types     float and     double.

For more information about General/FloatingPoint math, see http://en.wikipedia.org/wiki/Floating_point